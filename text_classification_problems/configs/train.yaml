# @package _global_
defaults:
  - _self_
  - paths: default.yaml
  - hydra: default.yaml
  - datamodule: ???
  - net: bert.yaml
  - logger: tensorboard.yaml
  - trainer: default.yaml

# Output directory is generated dynamically on each run
# following the pattern ${paths.log_dir}/${task_name}/${run_name}
task_name: train/${datamodule.dataset_name}
run_name: ${seed}_${now:%Y-%m-%d}_${now:%H-%M-%S}

# seed for random number generators in pytorch, numpy and python.random
seed: 12345

gpus: 2
learning_rate: 5e-5
max_epochs: 10
dev_run: False

# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True

# simply provide checkpoint path to resume training
ckpt_path: null
