# @package _global_
defaults:
  - _self_
  - paths: default.yaml
  - hydra: default.yaml
  - datamodule: binary_cifar10.yaml
  - net: wrn.yaml
  - logger: tensorboard.yaml
  - trainer: default.yaml

# Output directory is generated dynamically on each run
# following the pattern ${paths.log_dir}/${task_name}/runs/${run_name}
task_name: train
run_name: ${datamodule.dataset_name}_${net.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
gpus: 2

# seed for random number generators in pytorch, numpy and python.random
seed: 12345

learning_rate: 1e-3

# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True

# simply provide checkpoint path to resume training
ckpt_path: null
